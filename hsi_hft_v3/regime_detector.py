"""
RegimeDetector v1.1 - å·¥ç¨‹åŒ–ä¸¤å±‚çŠ¶æ€ç³»ç»Ÿ

æ ¸å¿ƒæ”¹è¿›ï¼š
1. å­—æ®µå£å¾„ç»Ÿä¸€ + å¥åº·åº¦é—¸é—¨
2. åˆ†ä½æ•°è¯„åˆ†åˆ¶ï¼ˆé¿å…ORè¿›å…¥ANDé€€å‡ºé”æ­»ï¼‰
3. Actionå±‚ä¸¤é˜¶æ®µgatingï¼ˆç¡®ä¿å¯äº¤æ˜“é©»ç•™é•¿åº¦ï¼‰
4. Micro/Actionåˆ†åˆ«çš„min_residence
5. è¿ç»­ç½®ä¿¡åº¦é©±åŠ¨å¹³æ»‘

åŸºäºç”¨æˆ·è¯Šæ–­æ–¹æ¡ˆv1.1
"""

import numpy as np
import pandas as pd
from typing import Dict, Tuple, Optional, List
from collections import deque, defaultdict


# ============================================
# 1. å­—æ®µå£å¾„ç»Ÿä¸€ä¸å¥åº·åº¦é—¸é—¨
# ============================================


class FeatureHealthMonitor:
    """
    ç‰¹å¾å¥åº·åº¦ç›‘æ§

    æ£€æŸ¥é¡¹ï¼š
    1. éé›¶æ¯”ä¾‹ï¼ˆ>50%ï¼‰
    2. æ ‡å‡†å·®ï¼ˆé¿å…å¸¸æ•°ï¼‰
    3. æå€¼åˆ†ä½æ•°è·¨åº¦ï¼ˆp95-p05 > thresholdï¼‰
    """

    def __init__(self, window=100):
        self.window = window
        self.history = defaultdict(lambda: deque(maxlen=window))

    def update(self, feature_name: str, value: float):
        """æ›´æ–°ç‰¹å¾å†å²"""
        self.history[feature_name].append(value)

    def is_healthy(self, feature_name: str) -> Tuple[bool, str]:
        """
        åˆ¤æ–­ç‰¹å¾æ˜¯å¦å¥åº·

        Returns:
            (is_healthy, reason)
        """
        if feature_name not in self.history:
            return False, "no_data"

        values = list(self.history[feature_name])
        if len(values) < 10:
            return False, "insufficient_samples"

        # æ£€æŸ¥1ï¼šéé›¶æ¯”ä¾‹
        non_zero_ratio = sum(1 for v in values if abs(v) > 1e-9) / len(values)
        if non_zero_ratio < 0.05:  # Relaxed for ETF from 0.5 -> 0.05
            return False, f"low_non_zero_ratio_{non_zero_ratio:.2f}"

        # æ£€æŸ¥2ï¼šæ ‡å‡†å·®
        std = np.std(values)
        if std < 1e-6:
            return False, f"constant_std_{std:.2e}"

        # æ£€æŸ¥3ï¼šæå€¼è·¨åº¦
        p95 = np.percentile(values, 95)
        p05 = np.percentile(values, 5)
        span = p95 - p05
        if span < 1e-6:
            return False, f"low_span_{span:.2e}"

        return True, "ok"


class CanonicalFeatureMapper:
    """
    å­—æ®µå£å¾„ç»Ÿä¸€æ˜ å°„å™¨

    æ‰€æœ‰åˆ«åæ˜ å°„åˆ°canonical key
    """

    CANONICAL_KEYS = {
        "vpin": ["tgt_VPIN_100", "VPIN_100", "vpin_z", "VPIN"],
        "spread_bps": ["tgt_spread_bps", "spread_bps", "spread"],
        "depth": ["depth", "total_depth"],
    }

    @classmethod
    def get_canonical_value(cls, data: Dict, canonical_key: str) -> Optional[float]:
        """
        ä»dataä¸­è·å–canonical keyå¯¹åº”çš„å€¼

        å°è¯•æ‰€æœ‰å¯èƒ½çš„åˆ«åï¼Œè¿”å›ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„
        """
        aliases = cls.CANONICAL_KEYS.get(canonical_key, [canonical_key])

        for alias in aliases:
            if alias in data:
                val = data[alias]
                if val is not None and not np.isnan(val):
                    return float(val)

        return None


# ============================================
# 2. å¢å¼ºçš„æ—¥å†…åˆ†ä½æ•°åŸºçº¿
# ============================================


class IntradayQuantileBaseline:
    """
    æ—¥å†…åˆ†ä½æ•°åŸºçº¿ v1.1

    æ”¹è¿›ï¼š
    1. æ›´å¤šåˆ†ä½æ•°ï¼ˆp05, p10, p20, p50, p80, p90, p95, p99ï¼‰
    2. Sessionåˆ†ç¦»ï¼ˆæ—©ç›˜/åˆç›˜ï¼‰
    3. Out-of-sessionæ ‡è®°
    """

    # äº¤æ˜“æ—¶æ®µå®šä¹‰ï¼ˆæ¸¯è‚¡æ—¶é—´ï¼‰
    SESSIONS = {
        "morning": ((9, 30), (12, 0)),  # æ—©ç›˜
        "afternoon": ((13, 0), (16, 0)),  # åˆç›˜
    }

    def __init__(self, bucket_minutes=5):
        self.bucket_minutes = bucket_minutes

        # {session: {bucket_id: {'metric': [values]}}}
        self.historical_data = defaultdict(
            lambda: defaultdict(lambda: defaultdict(list))
        )

        # è®¡ç®—å¥½çš„åˆ†ä½æ•°è¡¨
        self.quantile_table = {}

        # åˆ†ä½æ•°é›†åˆ
        self.quantiles = [0.05, 0.10, 0.20, 0.50, 0.80, 0.90, 0.95, 0.99]

    def _get_session_and_bucket(self, timestamp_ms: int) -> Tuple[Optional[str], int]:
        """
        è·å–sessionå’Œbucket_id

        Returns:
            (session_name, bucket_id) æˆ– (None, -1) if out of session
        """
        dt = pd.Timestamp(timestamp_ms, unit="ms", tz="Asia/Shanghai")
        hour, minute = dt.hour, dt.minute

        for session_name, ((start_h, start_m), (end_h, end_m)) in self.SESSIONS.items():
            # æ£€æŸ¥æ˜¯å¦åœ¨è¯¥sessionå†…
            time_minutes = hour * 60 + minute
            start_minutes = start_h * 60 + start_m
            end_minutes = end_h * 60 + end_m

            if start_minutes <= time_minutes < end_minutes:
                # è®¡ç®—sessionå†…çš„bucket
                minutes_since_session_start = time_minutes - start_minutes
                bucket_id = minutes_since_session_start // self.bucket_minutes
                return session_name, bucket_id

        return None, -1  # Out of session

    def add_observation(
        self, timestamp_ms: int, vpin: float, spread: float, depth: float
    ):
        """æ·»åŠ è§‚æµ‹å€¼"""
        session, bucket_id = self._get_session_and_bucket(timestamp_ms)

        if session is None:
            return  # è·³è¿‡ä¼‘å¸‚æ—¶é—´

        self.historical_data[session][bucket_id]["vpin"].append(vpin)
        self.historical_data[session][bucket_id]["spread"].append(spread)
        self.historical_data[session][bucket_id]["depth"].append(depth)

    def compute_quantiles(self):
        """è®¡ç®—æ‰€æœ‰sessionå’Œbucketçš„åˆ†ä½æ•°"""
        for session in self.historical_data:
            for bucket_id in self.historical_data[session]:
                key = f"{session}_{bucket_id}"
                self.quantile_table[key] = {}

                for metric in ["vpin", "spread", "depth"]:
                    data = self.historical_data[session][bucket_id][metric]

                    if len(data) > 10:
                        self.quantile_table[key][metric] = {
                            f"p{int(q*100):02d}": np.percentile(data, q * 100)
                            for q in self.quantiles
                        }
                    else:
                        # æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨é»˜è®¤å€¼
                        self.quantile_table[key][metric] = {
                            f"p{int(q*100):02d}": 0.0 for q in self.quantiles
                        }

    def get_threshold(self, timestamp_ms: int, metric: str, percentile: str) -> float:
        """è·å–åŠ¨æ€é˜ˆå€¼"""
        session, bucket_id = self._get_session_and_bucket(timestamp_ms)

        if session is None:
            return 0.0

        key = f"{session}_{bucket_id}"
        if key in self.quantile_table:
            return self.quantile_table[key].get(metric, {}).get(percentile, 0.0)

        return 0.0

    def get_rank(self, timestamp_ms: int, metric: str, value: float) -> float:
        """
        è·å–valueåœ¨å†å²åˆ†å¸ƒä¸­çš„åˆ†ä½æ•°ä½ç½®ï¼ˆrankï¼‰

        Returns:
            0.0-1.0ï¼Œè¡¨ç¤ºvalueåœ¨è¯¥bucketå†å²åˆ†å¸ƒä¸­çš„ä½ç½®
        """
        session, bucket_id = self._get_session_and_bucket(timestamp_ms)

        if session is None:
            return 0.5  # é»˜è®¤ä¸­ä½æ•°

        data = self.historical_data[session][bucket_id].get(metric, [])
        if len(data) < 10:
            return 0.5

        # è®¡ç®—rankï¼ˆå°äºç­‰äºvalueçš„æ¯”ä¾‹ï¼‰
        rank = sum(1 for v in data if v <= value) / len(data)
        return rank


# ============================================
# 3. ä»·æ ¼åŠ¨åŠ›å­¦æŒ‡æ ‡ï¼ˆä¿æŒä¸å˜ï¼‰
# ============================================


class PriceDynamicsIndicators:
    """ä»·æ ¼åŠ¨åŠ›å­¦æŒ‡æ ‡ï¼ˆå·²éªŒè¯å¯ç”¨ï¼‰"""

    def __init__(self, window=20):
        self.window = window
        self.returns_buffer = deque(maxlen=window)
        self.mid_buffer = deque(maxlen=window)

    def update(self, mid: float, prev_mid: float):
        """æ›´æ–°ç¼“å†²åŒº"""
        if mid > 0 and prev_mid > 0:
            ret = np.log(mid / prev_mid)
        else:
            ret = 0.0

        self.returns_buffer.append(ret)
        self.mid_buffer.append(mid)

    def get_drift_to_vol_ratio(self) -> float:
        """æ¼‚ç§»-æ³¢åŠ¨æ¯”"""
        if len(self.returns_buffer) < 10:
            return 0.0

        rets = np.array(list(self.returns_buffer))
        drift = abs(rets.sum())
        vol = rets.std() * np.sqrt(len(rets))

        if vol < 1e-9:
            return 0.0

        return drift / vol

    def get_directional_consistency(self) -> float:
        """æ–¹å‘ä¸€è‡´æ€§"""
        if len(self.returns_buffer) < 10:
            return 0.0

        rets = np.array(list(self.returns_buffer))
        pos_ratio = (rets > 0).sum() / len(rets)

        return pos_ratio - 0.5

    def get_lag1_autocorr(self) -> float:
        """Lag-1è‡ªç›¸å…³"""
        if len(self.returns_buffer) < 10:
            return 0.0

        rets = np.array(list(self.returns_buffer))

        if len(rets) < 2:
            return 0.0

        corr = np.corrcoef(rets[:-1], rets[1:])[0, 1]

        return corr if not np.isnan(corr) else 0.0

    def get_mean_reversion_strength(self) -> float:
        """å‡å€¼å›å¤å¼ºåº¦"""
        if len(self.mid_buffer) < self.window:
            return 0.0

        mids = np.array(list(self.mid_buffer))
        ma = mids[:-5].mean() if len(mids) > 5 else mids.mean()

        deviation = (mids[-1] - ma) / (ma + 1e-9)

        if len(mids) >= 5:
            recent_trend = (mids[-1] - mids[-5]) / (mids[-5] + 1e-9)
            reversion_signal = -deviation * recent_trend
            return reversion_signal

        return 0.0

    def get_realized_vol(self) -> float:
        """å®ç°æ³¢åŠ¨"""
        if len(self.returns_buffer) < 10:
            return 0.0

        rets = np.array(list(self.returns_buffer))
        return rets.std()


# ============================================
# 4. ä¸¤å±‚Regimeæ£€æµ‹å™¨ v1.1
# ============================================


class TwoTierRegimeDetector_v11:
    """
    ä¸¤å±‚Regimeæ£€æµ‹å™¨ v1.1

    æ ¸å¿ƒæ”¹è¿›ï¼š
    1. âœ… å­—æ®µç»Ÿä¸€æ˜ å°„
    2. âœ… å¥åº·åº¦é—¸é—¨
    3. âœ… åˆ†ä½æ•°è¯„åˆ†åˆ¶ï¼ˆé¿å…é”æ­»ï¼‰
    4. âœ… è¿Ÿæ»é˜ˆå€¼ï¼ˆenter > exitï¼‰
    5. âœ… Actionä¸¤é˜¶æ®µgating
    6. âœ… Micro/Actionç‹¬ç«‹min_residence
    7. âœ… è¿ç»­ç½®ä¿¡åº¦
    """

    def __init__(
        self,
        baseline: IntradayQuantileBaseline,
        min_residence_micro=10,
        min_residence_action=15,
    ):
        self.baseline = baseline
        self.min_residence_micro = 30  # Increased for stability (was 10)
        self.min_residence_action = 50  # Increased for stability (was 15)

        # çŠ¶æ€
        self.current_micro = "normal"
        self.current_action = "neutral"
        self.residence_counter_micro = 0
        self.residence_counter_action = 0

        # ä»·æ ¼åŠ¨åŠ›å­¦
        self.dynamics = PriceDynamicsIndicators(window=40)  # Slower window (was 20)

        # å¥åº·åº¦ç›‘æ§
        self.health_monitor = FeatureHealthMonitor(
            window=300
        )  # Longer window for sticky prices (was 100)

        # å­—æ®µæ˜ å°„å™¨
        self.mapper = CanonicalFeatureMapper()

        # è¯„åˆ†å†å²ï¼ˆç”¨äºå¹³æ»‘ï¼‰
        self.illiquid_score_buffer = deque(maxlen=10)  # Smoother (was 5)
        self.highvol_score_buffer = deque(maxlen=10)  # Smoother (was 5)

    def detect(
        self, timestamp_ms: int, white_risk: Dict, mid: float, prev_mid: float
    ) -> Tuple[str, str, float]:
        """
        ä¸»æ£€æµ‹æ¥å£

        Returns:
            (micro_regime, action_regime, confidence)
        """
        # æ›´æ–°åŠ¨åŠ›å­¦
        self.dynamics.update(mid, prev_mid)

        # ğŸ”§ 1. å­—æ®µç»Ÿä¸€æ˜ å°„
        vpin = self.mapper.get_canonical_value(white_risk, "vpin") or 0.0
        spread = self.mapper.get_canonical_value(white_risk, "spread_bps") or 0.0
        depth = self.mapper.get_canonical_value(white_risk, "depth") or 10000.0

        # ğŸ”§ 2. æ›´æ–°å¥åº·åº¦
        self.health_monitor.update("vpin", vpin)
        self.health_monitor.update("spread", spread)
        self.health_monitor.update("depth", depth)

        # å¥åº·åº¦æ£€æŸ¥
        vpin_healthy, _ = self.health_monitor.is_healthy("vpin")
        spread_healthy, _ = self.health_monitor.is_healthy("spread")
        depth_healthy, _ = self.health_monitor.is_healthy("depth")

        # ğŸ”§ 3. Microå±‚ï¼šåˆ†ä½æ•°è¯„åˆ†åˆ¶
        new_micro, micro_conf = self._detect_micro_regime(
            timestamp_ms,
            vpin,
            spread,
            depth,
            vpin_healthy,
            spread_healthy,
            depth_healthy,
        )

        # Microåˆ‡æ¢æ§åˆ¶
        if new_micro != self.current_micro:
            if self.residence_counter_micro >= self.min_residence_micro:
                self.current_micro = new_micro
                self.residence_counter_micro = 0
                # Microåˆ‡æ¢æ—¶é‡ç½®Action
                self.current_action = "neutral"
                self.residence_counter_action = 0
        self.residence_counter_micro += 1

        # ğŸ”§ 4. Actionå±‚ï¼šä¸¤é˜¶æ®µgating
        if self.current_micro == "illiquid":
            # illiquidæ—¶Actionæ— æ„ä¹‰
            new_action = "neutral"
            action_conf = 0.0
        else:
            new_action, action_conf = self._detect_action_regime(timestamp_ms)

        # Actionåˆ‡æ¢æ§åˆ¶ï¼ˆä»…åœ¨Microç¨³å®šæ—¶å…è®¸ï¼‰
        if new_action != self.current_action and self.residence_counter_micro >= 5:
            if self.residence_counter_action >= self.min_residence_action:
                self.current_action = new_action
                self.residence_counter_action = 0
        self.residence_counter_action += 1

        # ç»¼åˆç½®ä¿¡åº¦
        overall_conf = micro_conf * (1.0 if self.current_micro != "illiquid" else 0.5)
        overall_conf *= max(0.5, action_conf) if action_conf > 0 else 0.7

        return self.current_micro, self.current_action, overall_conf

    def _detect_micro_regime(
        self,
        timestamp_ms: int,
        vpin: float,
        spread: float,
        depth: float,
        vpin_healthy: bool,
        spread_healthy: bool,
        depth_healthy: bool,
    ) -> Tuple[str, float]:
        """
        Microå±‚æ£€æµ‹ï¼šåˆ†ä½æ•°è¯„åˆ†åˆ¶

        æ ¸å¿ƒæ”¹è¿›ï¼šé¿å…ORè¿›å…¥ANDé€€å‡ºçš„é”æ­»
        """
        # è·å–rankï¼ˆåˆ†ä½æ•°ä½ç½®ï¼‰
        rank_spread = (
            self.baseline.get_rank(timestamp_ms, "spread", spread)
            if spread_healthy
            else 0.5
        )
        rank_depth = (
            self.baseline.get_rank(timestamp_ms, "depth", depth)
            if depth_healthy
            else 0.5
        )
        rank_vpin = (
            self.baseline.get_rank(timestamp_ms, "vpin", abs(vpin))
            if vpin_healthy
            else 0.5
        )

        # è®¡ç®—illiquid_score
        # ä»·å·®å¼‚å¸¸æ‰©å¤§ + æ·±åº¦å¼‚å¸¸å¡Œé™·
        illiquid_score = (
            max(0, rank_spread - 0.95) * 20 + max(0, 0.05 - rank_depth) * 20
        )
        self.illiquid_score_buffer.append(illiquid_score)
        illiquid_score_smooth = np.mean(self.illiquid_score_buffer)

        # è®¡ç®—highvol_score
        # VPINå°¾éƒ¨ + å®ç°æ³¢åŠ¨å°¾éƒ¨
        realized_vol = self.dynamics.get_realized_vol()
        rank_vol = 0.99 if realized_vol > 0.001 else 0.5  # ç®€åŒ–ï¼šå®é™…åº”è¯¥ä¹Ÿç”¨baseline

        highvol_score = max(0, rank_vpin - 0.90) * 10 + max(0, rank_vol - 0.90) * 10
        self.highvol_score_buffer.append(highvol_score)
        highvol_score_smooth = np.mean(self.highvol_score_buffer)

        # ğŸ”§ è¿Ÿæ»é˜ˆå€¼
        if self.current_micro == "illiquid":
            # é€€å‡ºé˜ˆå€¼æ›´å®½æ¾
            if illiquid_score_smooth < 0.3:  # é€€å‡ºé˜ˆå€¼
                pass  # å…è®¸é€€å‡ºåˆ°normal
            else:
                return "illiquid", 0.9

        if self.current_micro == "high_volatility":
            if highvol_score_smooth < 0.3:
                pass
            else:
                return "high_volatility", 0.85

        # è¿›å…¥åˆ¤æ–­
        if illiquid_score_smooth > 0.5:  # è¿›å…¥é˜ˆå€¼æ›´ä¸¥æ ¼
            return "illiquid", 0.9

        if highvol_score_smooth > 0.5:
            return "high_volatility", 0.85

        return "normal", 0.7

    def _detect_action_regime(self, timestamp_ms: int) -> Tuple[str, float]:
        """
        Actionå±‚æ£€æµ‹ï¼šä¸¤é˜¶æ®µgating

        æ”¹è¿›ï¼šç¡®ä¿å¯äº¤æ˜“é©»ç•™é•¿åº¦
        """
        # ğŸ”§ Stage 1: åŠ¨åŠ›å­¦ä¿¡æ¯gating
        realized_vol = self.dynamics.get_realized_vol()

        # è·å–è¯¥bucketçš„ä½åˆ†ä½é˜ˆå€¼
        vol_p10 = self.baseline.get_threshold(timestamp_ms, "spread", "p10")  # è¿‘ä¼¼

        if realized_vol < 1e-5:  # æä½æ³¢åŠ¨ï¼Œæ— åŠ¨åŠ›å­¦ä¿¡æ¯
            return "neutral", 0.3

        # ğŸ”§ Stage 2: è¯æ®ç«äº‰
        # trendingè¯æ®
        drift_vol = self.dynamics.get_drift_to_vol_ratio()
        dir_cons = abs(self.dynamics.get_directional_consistency())
        trending_score = (
            min(drift_vol / 1.5, 1.0) * 0.6 + min(dir_cons / 0.3, 1.0) * 0.4
        )

        # mean_revertingè¯æ®
        autocorr = self.dynamics.get_lag1_autocorr()
        mr_strength = self.dynamics.get_mean_reversion_strength()
        mr_score = 0.0
        if autocorr < -0.2:
            mr_score += min(abs(autocorr) / 0.5, 1.0) * 0.5
        if mr_strength > 0.3:
            mr_score += min(mr_strength / 0.8, 1.0) * 0.5

        # ç«äº‰é€‰æ‹©ï¼ˆéœ€è¦æ˜æ˜¾ä¼˜åŠ¿ï¼‰
        # ç«äº‰é€‰æ‹©ï¼ˆéœ€è¦æ˜æ˜¾ä¼˜åŠ¿ï¼‰
        # ETFè°ƒä¼˜ï¼š
        # 1. æé«˜Trendingé—¨æ§› (0.4 -> 0.6)
        # 2. é™ä½MRé—¨æ§› (0.4 -> 0.25)
        # 3. å¢åŠ ç«äº‰Buffer (0.15 -> 0.20)

        if trending_score > 0.60 and trending_score > mr_score + 0.20:
            return "trending", trending_score
        elif mr_score > 0.25 and mr_score > trending_score + 0.20:
            return "mean_reverting", mr_score
        else:
            return "neutral", 0.5


# å¯¼å‡ºæ¥å£ä¿æŒå…¼å®¹
TwoTierRegimeDetector = TwoTierRegimeDetector_v11
